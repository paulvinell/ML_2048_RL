{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradient in 2048\n",
    "This model plays 2048 and uses the following strategy:\n",
    "1. Play n games\n",
    "2. Calculate mean fitness function score\n",
    "3.\n",
    "    * Optimize the loss for the games with an above average fitness score (assume that every action at every state was correct).\n",
    "    * Optimize the negative of the loss for the games with a below average fitness score (assume that every action at every state was incorrect).\n",
    "4. Repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game imports\n",
    "This is made slightly more complicated than it has to be, because the target folder has characters that are disallowed in python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "dir_path = os.path.abspath('')\n",
    "dir_path = os.path.join(dir_path, '2048-python-custom-player')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, dir_path)\n",
    "\n",
    "import constants as c\n",
    "from tie_in import TieIn # Used to launch a game of 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set game constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.GRID_LEN_X = 3\n",
    "c.GRID_LEN_Y = 3\n",
    "c.PROBABILITY_4 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, InputLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear previous models from memory (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([InputLayer(input_shape=(c.GRID_LEN_X, c.GRID_LEN_Y, 1)),\n",
    "#                     Conv2D(32, kernel_size=2, activation='relu'),\n",
    "                    Conv2D(32, kernel_size=2, activation='relu'),\n",
    "                    Conv2D(64, kernel_size=2, activation='relu'),\n",
    "                    Dense(64, activation='relu'),\n",
    "                    Dense(4, activation='softmax')])\n",
    "\n",
    "#model.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=False), optimizer=keras.optimizers.Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Because the growth rate of the tiles in 2048 is exponential, we take log2 of all values, since linearly scaling values are more manageable. We also squish the values to be smaller in scale. For instance, 2 maps to 0.1, 1024 to 1, 8192 to 1.3, and 0 to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess(matrix):\n",
    "    non_zeros = np.nonzero(matrix)\n",
    "    matrix[non_zeros] = np.log2(matrix[non_zeros]) / np.log2(1024)\n",
    "    return matrix\n",
    "\n",
    "def one_hot(moves):\n",
    "    move_count = moves.shape[0]\n",
    "    oh = np.zeros((move_count, 4))\n",
    "    oh[np.arange(move_count), moves] = 1\n",
    "    return oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "Because of rotational symmetry, each game of 2048 corresponds to another set of three games (at least for square games). If we accept a move in one of the games as valid, then state and action's corresponding rotations must be equally valid. We use this argument to create more artificial games. Hopefully, this will also prevent a collapse in strategy where the model favors one corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_rotation_lookup = { 0: 2, 1: 3, 2: 1, 3: 0} # UP->LEFT, DOWN->RIGHT, LEFT->DOWN, RIGHT->UP\n",
    "def rotate_90_moves(moves):\n",
    "    move_count = moves.shape[0]\n",
    "    rot = np.zeros(moves.shape)\n",
    "    for i in range(move_count): # TODO: this is likely an inefficient way to implement this\n",
    "        rot[i] = move_rotation_lookup[rot[i]]\n",
    "    return rot.astype(int)\n",
    "\n",
    "def rotate_90_board(boards):\n",
    "    return np.rot90(boards, axes=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a custom player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPlayer():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.game_final = None # Contains the last state of the game\n",
    "        self.last_turn = -1\n",
    "    \n",
    "    def game_grid_init(self, game_grid):\n",
    "        pass\n",
    "\n",
    "    # TODO: maybe randomly pick a move, basing the probabilities on the softmax?\n",
    "    def play(self, game):\n",
    "        if game.move_count > self.last_turn:\n",
    "            self.last_turn = game.move_count\n",
    "        else:\n",
    "            print(\"ModelPlayer: stuck on turn {}\".format(game.move_count))\n",
    "            breakpoint()\n",
    "        \n",
    "        possible_directions = game.possible_directions()\n",
    "        possible_directions = np.array(possible_directions)\n",
    "        \n",
    "        model_input = np.array(game.matrix)\n",
    "        model_input = np.expand_dims(model_input, axis=-1) # Number of channels (1)\n",
    "        model_input = np.expand_dims(model_input, axis=0) # Batch dimension\n",
    "        \n",
    "        model_output = self.model.predict(model_input)\n",
    "        model_output = np.squeeze(model_output)\n",
    "        \n",
    "        model_mask = np.zeros(4)\n",
    "        model_mask[possible_directions] = 1\n",
    "        model_output *= model_mask # Only select from possible moves\n",
    "        \n",
    "        # Pick a move randomly based on how strongly the model suggests it\n",
    "        model_output_sum = np.sum(model_output)\n",
    "        \n",
    "        response = None\n",
    "        if model_output_sum > 0:\n",
    "            model_output_cumulative = np.cumsum(model_output) / np.sum(model_output)\n",
    "            cutoff_point = np.random.rand()\n",
    "            response = model_output_cumulative.searchsorted(cutoff_point)\n",
    "        \n",
    "        # response = np.argmax(model_output) # Picks the strongest response\n",
    "        if model_output_sum <= 0 or response is None or not np.any(possible_directions == response): # If we for any reason have picked an impossible move\n",
    "            response = np.random.choice(possible_directions) # Choose one of the possible ones at randoma\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def sleep(self, game, render):\n",
    "        if not render:\n",
    "            return 0 # Don't sleep when training\n",
    "\n",
    "        return np.log2(game.max_tile) / 30 # Go slower when it gets interesting\n",
    "    \n",
    "    def lost(self, game):\n",
    "        self.game_final = game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "#@tf.function\n",
    "def train_step(model, X, Y, punish=False):\n",
    "    with tf.GradientTape() as tape:\n",
    "        out = model(X, training=True)\n",
    "        out = tf.squeeze(out)\n",
    "        loss_val = loss_fn(Y, out)\n",
    "        if punish:\n",
    "            loss_val *= -1\n",
    "            \n",
    "    grads = tape.gradient(loss_val, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(game):\n",
    "    return game.move_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "PRINT_INTERVALS = 10 # Number of seconds between progress update (minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The actual loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "from functools import reduce\n",
    "\n",
    "last_print_time = time.time()\n",
    "history_fitness = []\n",
    "history_move_count = []\n",
    "history_max_tile = []\n",
    "\n",
    "print(\"Starting the training process.\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    games = []\n",
    "    \n",
    "    for i in range(BATCH_SIZE):\n",
    "        model_player = ModelPlayer(model)\n",
    "        ti = TieIn(model_player, render=False, log_history=True)\n",
    "        ti.start()\n",
    "        games.append(model_player.game_final)\n",
    "        \n",
    "        cur_time = time.time()\n",
    "        if cur_time - last_print_time >= PRINT_INTERVALS:\n",
    "            print(\"Playing: Processed: {}/{} in batch, {}/{} epochs.\".format(i+1, BATCH_SIZE, epoch, EPOCHS))\n",
    "            last_print_time = cur_time\n",
    "            \n",
    "    batch_mean_fitness = map(lambda g: fitness_function(g), games)\n",
    "    batch_mean_fitness = reduce(lambda sum_g, g: sum_g + g, batch_mean_fitness)\n",
    "    batch_mean_fitness = float(batch_mean_fitness) / BATCH_SIZE\n",
    "    \n",
    "    batch_mean_move_count = map(lambda g: g.move_count, games)\n",
    "    batch_mean_move_count = reduce(lambda sum_g, g: sum_g + g, batch_mean_move_count)\n",
    "    batch_mean_move_count = float(batch_mean_move_count) / BATCH_SIZE\n",
    "    \n",
    "    batch_mean_max_tile = map(lambda g: g.max_tile, games)\n",
    "    batch_mean_max_tile = reduce(lambda sum_g, g: sum_g + g, batch_mean_max_tile)\n",
    "    batch_mean_max_tile = float(batch_mean_max_tile) / BATCH_SIZE\n",
    "    \n",
    "    print(\"Status: Epoch {}: Mean fitness: {}, Move count: {}, Max tile: {}\".format(epoch, batch_mean_fitness, batch_mean_move_count, batch_mean_max_tile))\n",
    "    last_print_time = time.time()\n",
    "    history_fitness.append(batch_mean_fitness)\n",
    "    history_move_count.append(batch_mean_move_count)\n",
    "    history_max_tile.append(batch_mean_max_tile)\n",
    "    \n",
    "    good_games = filter(lambda g: fitness_function(g) >= batch_mean_fitness, games)\n",
    "    bad_games = filter(lambda g: fitness_function(g) < batch_mean_fitness, games)\n",
    "    \n",
    "    processed_count = 0\n",
    "    \n",
    "    for g in good_games:\n",
    "        X_base = np.array(g.board_history)\n",
    "        X_base = preprocess(X_base)\n",
    "        y_base = np.array(g.move_history) # Sparse encoding\n",
    "        \n",
    "        for rot in range(4):\n",
    "            X = X_base[..., np.newaxis] # Same as expand_dims(X, axis=-1)\n",
    "            Y = one_hot(y_base) # One-hot encoding\n",
    "\n",
    "            train_step(model, X, Y, punish=False)\n",
    "            \n",
    "            if rot < 3:\n",
    "                X_base = rotate_90_board(X_base)\n",
    "                y_base = rotate_90_moves(y_base)\n",
    "\n",
    "            if cur_time - last_print_time >= PRINT_INTERVALS:\n",
    "                print(\"Training: Processed: {}/{} in batch, {}/{} epochs.\".format(processed_count, BATCH_SIZE, epoch, EPOCHS))\n",
    "                last_print_time = cur_time\n",
    "        \n",
    "    for g in bad_games:\n",
    "        X_base = np.array(g.board_history)\n",
    "        X_base = preprocess(X_base)\n",
    "        y_base = np.array(g.move_history) # Sparse encoding\n",
    "        \n",
    "        for rot in range(4):\n",
    "            X = X_base[..., np.newaxis] # Same as expand_dims(X, axis=-1)\n",
    "            Y = one_hot(y_base) # One-hot encoding\n",
    "\n",
    "            train_step(model, X, Y, punish=True)\n",
    "            \n",
    "            if rot < 3:\n",
    "                X_base = rotate_90_board(X_base)\n",
    "                y_base = rotate_90_moves(y_base)\n",
    "\n",
    "            if cur_time - last_print_time >= PRINT_INTERVALS:\n",
    "                print(\"Training: Processed: {}/{} in batch, {}/{} epochs.\".format(processed_count, BATCH_SIZE, epoch, EPOCHS))\n",
    "                last_print_time = cur_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model and training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model.save('policy_gradient.h5')\n",
    "\n",
    "\n",
    "policy_gradient_history = { 'history_fitness': history_fitness,\n",
    "                           'history_move_count': history_move_count,\n",
    "                           'history_max_tile': history_max_tile }\n",
    "file = open('policy_gradient_history.pickle', 'wb')\n",
    "pickle.dump(policy_gradient_history, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('policy_gradient.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_player = ModelPlayer(model)\n",
    "ti = TieIn(model_player, render=True, log_history=False)\n",
    "ti.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
